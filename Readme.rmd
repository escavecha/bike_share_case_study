---
title: "Case Study: How Does a Bike-Share Navigate Speedy Success?"
author: John Lee
date: < the current date DD/MM/YYYY >
output: html_vignette
editor_options: 
  markdown: 
    wrap: 120
---

## Case Study: How Does a Bike-Share Navigate Speedy Success?

This work is an output of the capstone project for *Google Data Analytics Professional Certificate*
([link](https://www.coursera.org/professional-certificates/google-data-analytics)).

This fictional case study packet is based on the *Divvy* case study, "'Sophisticated, Clear, and Polished': Divvy and
Data Visualization" written by Kevin Hartman ([link](https://artscience.blog/home/divvy-dataviz-case-study)).

Below describes how the bike-sharing user patterns differ in given data set, and provides findings and suggestions based
on the result of the analysis.

> Note: *Divvy* is a bike share system across Chicago and Evanston, consisted of a fleet of bikes that are locked into a
> network of docking stations throughout the region. The bikes can be unlocked from one station and returned to any
> other station in the system. *Divvy* is a program of the Chicago Department of Transportation (CDOT), which owns the
> city's bikes, stations and vehicles ([Link](https://divvybikes.com/about)).

### Scenario

You are a junior data analyst working in the marketing analyst team at *Cyclistic*, a bike-share company in Chicago. The
marketing director believes the company's future success depends on maximizing the number of annual memberships.
Therefore, your team wants to understand how casual riders and annual members use *Cyclistic* bikes differently.

From these insights, your team will design a new marketing strategy to convert casual riders into annual members. But
first, *Cyclistic* executives must approve your recommendations, so they must be backed up with compelling data insights
and professional data visualizations.

In 2016, *Cyclistic* launched a bike-share offering. Since then, the program has grown to a fleet of 5,824 bicycles that
are geo-tracked and locked into a network of 692 stations across Chicago. The bikes can be unlocked from one station and
returned to any other station in the system anytime.

Until now, *Cyclistic*'s marketing strategy relied on building general awareness and appealing to broad consumer
segments.

One approach that helped make these things possible was the flexibility of its pricing plans: single-ride passes,
full-day passes, and annual memberships. Customers who purchase single-ride or full-day passes are referred to as
"Casual riders"(**Casual**). Customers who purchase annual memberships are "Cyclistic members"(**Member**).

*Cyclistic*'s finance analysts have concluded that annual members are much more profitable than casual riders. Although
the pricing flexibility helps *Cyclistic* attract more customers, marketing director believes that maximizing the number
of annual members will be key to future growth.

Rather than creating a marketing campaign that targets all-new customers, she believes there is a very good chance to
convert casual riders into members. She notes that casual riders are already aware of the *Cyclistic* program.

The marketing director set a clear goal: Design marketing strategies aimed at converting casual riders into annual
members. In order to do that, however, the marketing analyst team needs to better understand:

1.  How annual members and casual riders differ
2.  Why casual riders would buy a membership
3.  And how digital media could affect their marketing tactics.

She and her team are interested in analyzing the *Cyclistic* historical bike trip data to identify trends. You have
assigned to the first question to the answer: **How do annual members and casual riders use Cyclistic bikes
differently?**

### Statement of Purpose

Use the given data set for 12-month period, analyze different patterns and present findings and suggestions along with
the result of analysis. R has used for this work.

### Data source

By the time I have complete this case study, *Cyclistic*'s historical trip data from 2013 to July 2023 has provided for analysis:
([link](https://divvy-tripdata.s3.amazonaws.com/index.html))

> Note: The datasets have a different name, as *Cyclistic* is a fictional company. The data has been made available for
> case study by *Motivate International Inc.* under this license
> ([link](https://ride.divvybikes.com/data-license-agreement)).

In this study, I have downloaded quarterly data in 2019. Each file is provided with `zip` format. each file contains a
`csv` file.

First, data pre-processing work is following in below steps.

1.  import libraries for use.
2.  import data from downloaded files.
3.  check variable names, attributes in datasets to merge them into a single dataframe.
4.  clean up data to prepare analysis.

### Data Pre-processing

#### Step 1. Install and import libraries

```{r pkg install}
install.packages("tidyverse")
install.packages("lubricate")
install.packages("ggplot2")
install.packages("readr")
install.packages("dplyr")
install.packages("gridExtra")
```

```{r load library}
setwd("C:/Google_DA_CaseStudy")
library(tidyverse)
library(lubridate)
library(ggplot2)
library(readr)
library(dplyr)
library(gridExtra)
```

#### Step 2. import data from downloaded files

I chose `Divvy_Trips_2019_Q1.zip` to `Divvy_Trips_2019_Q4.zip` files to use. 

```{r import data}
Trips_2019_Q1 <- read_csv("Divvy_Trips_2019_Q1.csv", show_col_types = FALSE)
Trips_2019_Q2 <- read_csv("Divvy_Trips_2019_Q2.csv", show_col_types = FALSE)
Trips_2019_Q3 <- read_csv("Divvy_Trips_2019_Q3.csv", show_col_types = FALSE)
Trips_2019_Q4 <- read_csv("Divvy_Trips_2019_Q4.csv", show_col_types = FALSE)
```

Quick check for imported dataframe sizes.

-   Trips_2019_Q1: 365,069 rows x 12 columns
-   Trips_2019_Q2: 1,108,163 rows x 12 columns
-   Trips_2019_Q3: 1,640,718 rows x 12 columns
-   Trips_2019_Q4: 704,054 rows x 12 columns

#### Step 3. check for column names to quick review

To merge data frames into one, column names and attributes should consistent each other.

```{r inspect columns}
colnames(Trips_2019_Q1)
colnames(Trips_2019_Q2)
colnames(Trips_2019_Q3)
colnames(Trips_2019_Q4)
```

Except `Trips_2019_Q2`, column names in other dataframes are identical. While `Trips_2019_Q2` shows different column
names, but the attributes look same. Rename the column names to match to the others.

```{r rename column}
Trips_2019_Q2 <- rename(Trips_2019_Q2,
                        trip_id = "01 - Rental Details Rental ID",
                        start_time = "01 - Rental Details Local Start Time",
                        end_time = "01 - Rental Details Local End Time",
                        bikeid = "01 - Rental Details Bike ID",
                        tripduration = "01 - Rental Details Duration In Seconds Uncapped",
                        from_station_id = "03 - Rental Start Station ID",
                        from_station_name = "03 - Rental Start Station Name",
                        to_station_id = "02 - Rental End Station ID",
                        to_station_name = "02 - Rental End Station Name",
                        usertype= "User Type",
                        gender = "Member Gender",
                        birthyear = "05 - Member Details Member Birthday Year"
                        )
```

Inspect the data types for each column. If all matches, then the identical functions will return 'TRUE'.

```{r inspect data type}
df1_types <- sapply(Trips_2019_Q1, class)
df2_types <- sapply(Trips_2019_Q2, class)
df3_types <- sapply(Trips_2019_Q3, class)
df4_types <- sapply(Trips_2019_Q4, class)
identical(df1_types, df2_types)
identical(df1_types, df3_types)
identical(df1_types, df4_types)
```

Combine all quarterly data into single dataframe to show annual data. Keep this original dataframe for backup.

```{r merge dataframes}
Trips_2019v0 <- bind_rows(Trips_2019_Q1, Trips_2019_Q2, Trips_2019_Q3, Trips_2019_Q4)
```

#### Step 4. Clean up data to prepare analysis.

Drop irrelevant columns (`gender`,`birthyear`) then save to the new data frame.

```{r drop columns}
Trips_2019v1 <- Trips_2019v0 %>% select(-c(gender, birthyear))
```

Add a new column `duration_min` to show trip duration time taken in minutes.

```{r new duration}
Trips_2019v1$duration_min <- as.numeric(difftime(Trips_2019v1$end_time, Trips_2019v1$start_time, units = "mins"))

```

According to the values in a new column `duration_min`, current `tripduration` column indicates values in seconds. To
avoid confusion, change the column name accordingly.

```{r rename duration}
names(Trips_2019v1)[names(Trips_2019v1) == 'tripduration'] <- "duration_sec"

```

Check the dataframe `Trip_2019v1` using `summary()` function.

```{r}
summary(Trips_2019v1)
```
There are two things noticed from `duration_min`. 
First, The Minimum value in duration_min is -56.37. Since this column has calculated based on the time difference between
`end_time` and `start_time`, negative value seems strange. The packet explains that those values are from the bikes are taken out of services. So I will delete those rows from the data.

```{r remove false duration}
Trips_2019v1 <- subset(Trips_2019v1, duration_min >= 0)
```

Second, Compared to Mean and 3rd Quartile value, the Max value is far too extreme. Meaning that the bike has turned in 177200 minutes later (or 123 days) since `start_time`. How to handle those cases? 

In the real-world, *Divvy* mentiones in FAQ as below:
> (Quote) Do not under any circumstances leave your bike unattended; if you left your bike outside of a station please return immediately and redock your bike. Please know that bikes missing for longer than 24 hours can result in a $1,200 fee (plus tax) charged to the account holder that took out the bike ([link](https://help.divvybikes.com/hc/en-us/articles/360033123412-My-bike-was-lost-or-stolen)).

Thus, I will assume that the data with `duration_min` is more than 24 hours (1440 min) is abnormal instances, and also exclude from the scope of analysis. Let's check how many rows fit in this criteria.

```{r}
count <- sum(Trips_2019v1$duration_min > 1440)
print(count)
```
Luckily, those 'unusual' rides are takes negligible portion from the dataset. Delete those rows likewise.
```{r}
Trips_2019v1 <- subset(Trips_2019v1, duration_min <= 1440)
```

(Optional) If your OS language is not set to English, then it would be better to set them to English when extracting
dates.

```{r}
Sys.setlocale("LC_TIME", "en_US.UTF-8")
```

Extract data and time information from `start_time` and `end_time`. I want to get the year, month, start/end date, and
weekday information.

```{r extract date/time}
Trips_2019v1$year <- as.integer(format(Trips_2019v1$start_time, "%Y"))
Trips_2019v1$month <- format(Trips_2019v1$start_time, "%b")
Trips_2019v1$days <- weekdays(Trips_2019v1$start_time)
Trips_2019v1$start_date <- as.integer(format(Trips_2019v1$start_time, "%d"))
Trips_2019v1$end_date <- as.integer(format(Trips_2019v1$end_time, "%d"))
```

And convert current `start_time` and `end_time` to show time data only.

```{r convert time}
Trips_2019v1$start_time <- format(Trips_2019v1$start_time, "%H:%M:%S")
Trips_2019v1$end_time <- format(Trips_2019v1$end_time, "%H:%M:%S")
```

As we don't need values in float, convert other columns in numeric to integer.

```{r convert to int}
cols_to_int <- c("trip_id",
                 "bikeid",
                 "from_station_id",
                 "to_station_id",
                 "duration_min",
                 "duration_sec")
Trips_2019v1[cols_to_int] <- lapply(Trips_2019v1[cols_to_int], as.integer)
```

I will remove redundant `duration_sec` column, then make a Copy of a new dataframe.

```{r}
Trips_2019v2 <- subset(Trips_2019v1, select = -c(duration_sec))

```

Rearrange columns order for better visibility of titles.

```{r}
Trips_2019v2 <- Trips_2019v2[, c("trip_id",
                                 "bikeid",
                                 "usertype",
                                 "year",
                                 "month",
                                 "start_date",
                                 "days",
                                 "start_time",
                                 "end_date",
                                 "end_time",
                                 "from_station_id",
                                 "from_station_name",
                                 "to_station_id",
                                 "to_station_name",
                                 "duration_min")]
```

Let's check what kind of variables exist in `usertype`.
```{r}
table(Trips_2019v2$usertype)
```

There are only two types of variables in the `usertype`. Update the terms to align with the terms in the scenario
(**Casual**, **Member**). At the same time, change the column name to `membership`.

```{r membership}
Trips_2019v2 <- Trips_2019v2 %>% mutate(usertype = recode(usertype,
                                          "Customer" = 'Casual',
                                          "Subscriber" = 'Member'))
names(Trips_2019v2)[names(Trips_2019v2) == 'usertype'] <- "membership"
```

Reorder the order of days to appear.

```{r}
Trips_2019v2$days <- ordered(Trips_2019v2$days, levels=c("Monday",
                                                         "Tuesday",
                                                         "Wednesday",
                                                         "Thursday",
                                                         "Friday",
                                                         "Saturday",
                                                         "Sunday"))
```

Check for the occurrences of values in this column.

```{r check occurrence}
# Find the number of unique values in column from_station_id
n_unique_tripid <- length(unique(Trips_2019v2$trip_id))
n_unique_usertype <- length(unique(Trips_2019v2$membership))
n_unique_bikeid <- length(unique(Trips_2019v2$bikeid))
n_unique_from_station_id <- length(unique(Trips_2019v2$from_station_id))
n_unique_to_station_id <- length(unique(Trips_2019v2$to_station_id))
print(paste("Number of total bikes in 2019:", n_unique_bikeid)) # 6017
print(paste("Number of bike stations in 2019:", n_unique_from_station_id)) # 616
print(paste("Total trips made in 2019:", n_unique_tripid)) # 3817991
```

Compared to the description in scenario, the fleet size has expanded from 5824 to 6017, while number of stations has decreased from 692 to 616, since 2016.

The pre-processing part is now complete. So far, following works have done:

1.  Import data files and converted to dataframe
2.  Match attributes in each dataframe to merge them into one
3.  Remove, add, and modify the variables and attributes as necessary
4.  Build a clean dataframe from the original for further analysis.

Now, continue with the data analysis.

### Data Analysis

This analysis needs to provide the answer to given question: How do annual members and casual riders use Cyclistic bikes
differently? Further analysis will focus to compare the patterns between the membership types, *Casual* and *Member*.

#### Step 1. Check for statistics

First, check for the fraction of rides made by membership.

```{r check fraction}
# Calculate the table of membership
membership_table <- table(Trips_2019v2$membership)

# Calculate the fraction in membership
membership_fraction <- prop.table(membership_table)

# Combine the tables
result <- cbind(membership_table, membership_fraction)

# Print the result
print(result)
```

Majority of the rides are made by *members* (about 77% of total rides). Let's compare statistics for riding times in
minutes (`duration_min`).

```{r check stats}
# Calculate the mean, median, max, and min of duration_min grouped by membership
mean_duration <- aggregate(Trips_2019v2$duration_min ~ Trips_2019v2$membership, FUN=mean)
median_duration <- aggregate(Trips_2019v2$duration_min ~ Trips_2019v2$membership, FUN=median)
max_duration <- aggregate(Trips_2019v2$duration_min ~ Trips_2019v2$membership, FUN=max)
min_duration <- aggregate(Trips_2019v2$duration_min ~ Trips_2019v2$membership, FUN=min)

# Combine the results into a single data frame
result <- data.frame(Membership = mean_duration[, 1],
                     Mean = mean_duration[, 2],
                     Median = median_duration[, 2],
                     Max = max_duration[, 2],
                     Min = min_duration[, 2])

# Print the result
print(result)
```

Maximum and minimum values are identical for both membership types. However, the mean value suggests difference between
users: *Casual* users ride longer than *Members* per ride, even though their portion of total usage is less than 25%. On
the contrary, *members* ride for short distance, but more frequently. To identify the detail patterns in this difference, I will start to break those patters from monthly to hourly scale in following analysis.

#### Step 2. Monthly patterns
Let's visualize the monthly patterns by membership.

```{r fig 1}
# Create ordered factor for months
month_levels <- c("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec")
Trips_2019v2$month <- factor(Trips_2019v2$month, levels = month_levels, ordered = TRUE)

# Calculate mean duration by membership and month
df_months <- Trips_2019v2 %>%
  group_by(membership, month) %>%
  summarize(mean_duration = mean(duration_min), .groups = "drop")

# Create line chart
p1 <- ggplot(df_months, 
             aes(x = month, 
                 y = mean_duration, 
                 color = membership, 
                 group = membership)) +
  geom_line() +
  labs(x = "Month", 
       y = "Avg. Duration (min)",
       title = "Fig 1. Average Ride Duration by Membership, Monthly (2019)") +
  geom_text(aes(label = round(mean_duration, 1)), vjust = -0.5)

print(p1)
ggsave("p1_monthly_duration.png", plot = p1)
```
Key findings:

1. on average, `casual` users use the bike for around 29 to 41 minutes.
2. on average, `members` use the bike around 11 to 14 minutes.
3. average duration is the least in February for `casual` riders.
4. average duration is the least in November and December for 'members'.
5. Compared to 'casual` riders, the variance in the trend is smaller for `members`.

To see the patterns in different angle, plot the data for number of riders for monthly.
This time I will use the average number of rides per station.

```{r fig 2}
df_monthly_mean <- Trips_2019v2 %>%
  group_by(membership, month) %>%
  summarise(mean_trips = n() / n_unique_from_station_id, .groups = "drop")

# Plot the data as a line chart with points and labels
p2 <- ggplot(df_monthly_mean, aes(x = month,
                                    y = mean_trips,
                                    color = membership,
                                    group = membership)) +
  geom_line() +
  geom_point() +
  labs(title = "Fig 2. Average Number of Rides per Station by Membership, Monthly (2019)",
       x = "Months",
       y = "Avg. Number of Rides / Station") +
  geom_text(aes(label = round(mean_trips, 0)), vjust = -0.8) +
  annotate("text", x = 6, y = Inf,
           label = paste("Total number of stations:",n_unique_from_station_id),
           hjust = 1.1, vjust = 2)

print(p2)
ggsave("p2_monthly_rides_per_station.png", plot = p2)
```
Key findings: 

1. the least rides are made in February, while the most rides are made in August for both membership types.
2. Ride usage are similar to the monthly weather condition. people rides less during winter, while rides more during summer. 

Recommendation:
We can schedule the annual maintenance plan of the fleets focused on during winter time to allow more availability of the bikes for rest of the seasons. 

#### Step 3. Daily patterns

Let's take a look in detail for daily patterns. Plot a line chart for daily usage patterns.

```{r fig 3}
df_daily_mean_duration <- aggregate(Trips_2019v2$duration_min ~ Trips_2019v2$membership +
  Trips_2019v2$days, FUN=mean)
colnames(df_daily_mean_duration) <- c("membership", "days", "mean_duration")

# Create line chart
p3 <- ggplot(df_daily_mean_duration, aes(x = days,
                                   y = mean_duration,
                                   group = membership,
                                   color = membership)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday")) +
  labs(x = "Days",
       y = "Avg. Duration (min)",
       title = "Fig 3. Average Ride Duration by Membership, daily (2019)") +
  geom_text(aes(label = round(mean_duration, 1)), vjust = -0.5)

# Display ans save plot
print(p3)
ggsave("p1_daily_duration.png", plot = p3)
```

Roughly speaking, *members* ride a bike daily, about 13 to 16 minutes in average. However, *casual* users ride about 50
to 60 minutes in average.

Although the difference is visible, still the purpose of the ride is still unclear. Let's analyze the daily patterns for
number or rides.

```{r fig 4}
df_daily_no_mean <- Trips_2019v2 %>% # mean no per station
  group_by(membership, days) %>%
  summarise(mean_daily = n() / n_unique_from_station_id, .groups = "drop")

# Convert membership and days to factor variables
df_daily_no_mean$membership <- as.factor(df_daily_no_mean$membership)
df_daily_no_mean$days <- as.factor(df_daily_no_mean$days)

p4 <- ggplot(df_daily_no_mean, aes(x = days,
                                    y = mean_daily,
                                    color = membership,
                                    group = membership)) +
  geom_line() +
  geom_point() +
  labs(title = "Fig 4. Average Number of Rides per Station by membership, Daily (2019)",
       x = "Days",
       y = "Avg. No. of Rides / Station") +
  geom_text(aes(label = round(mean_daily, 0)), vjust = -0.8) +
  annotate("text", x = Inf, y = Inf,
           label = paste("Total number of stations:", n_unique_from_station_id),
           hjust = 1.1, vjust = 2)

print(p4)
ggsave("p4_weekly_rides_per_station.png", plot = p4)
```

Now the pattern is more understandable. *Members* use the ride for Monday to Friday, then drops on Saturday and Sunday.
We can assume that those rides are mostly used for commute to work, which make senses when the average ride duration is
less than 20 minutes. At the same time, rides are increased during weekends for *casual* riders, as we may assume that
those are leisurely purpose. Still, *casual* riders are using the bike on the weekdays too.

> Key finding: The purpose of rides are different for membership types. *Members* mainly use the ride during weekdays,
> whiile *casual* riders mostly use for weekends.

Let's take a look on the patterns on hourly basis on each day to verify this finding. I will plot the charts for
weekdays and weekends to see the difference.

#### Step 4. Hourly patterns

```{r fig 5}
weekday_data_mean <- Trips_2019v2 %>%
  filter(days %in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday")) %>%
  mutate(hour = hour(hms(start_time))) %>%
  group_by(membership, hour) %>%
  summarise(number_of_rides = n() / n_unique_from_station_id,
            average_duration = mean(duration_min), .groups = "drop") %>%
  arrange(membership, hour)

# Create the first plot
p4a_weekday_mean <- weekday_data_mean %>%
  ggplot(aes(x = hour,
             y = average_duration,
             color = membership,
             group = membership)) +
  geom_line() +
  geom_point() +
  labs(x = 'Hour', 
       y = 'Avg. duration (min)',
       title = 'Fig 5a. Average Duration by Membership on Weekdays, Hourly (2019)')

# Create the second plot
p4b_weekday_mean <- weekday_data_mean %>%
  ggplot(aes(x = hour,
             y = number_of_rides,
             color = membership,
             group = membership)) +
  geom_line() +
  geom_point() +
  scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) +
  labs(x = 'Hour', 
       y = 'No. of rides',
       title = 'Fig 5b. Number of Rides per Station by Membership on Weekdays, Hourly (2019)') +
  annotate("text", x = 0, y = Inf,
           label = paste("Total number of stations:", n_unique_from_station_id),
           hjust = 0, vjust = 0.9)

p4_weekdays_mean <- grid.arrange(p4a_weekday_mean, p4b_weekday_mean, ncol=1)
print(p4_weekdays_mean)
ggsave("p4_weekdays.png", plot = p4_weekdays_mean)
```
